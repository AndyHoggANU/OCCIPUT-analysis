{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EKE\n",
    "\n",
    "This notebook takes raw, 5-daily geostrophic surface velocity data from the `OCCIPUT` simulations (provided by Sally Close, calculated from detrended SLA) and estimates `EKE(x,y,t)`. It then resamples down to monthly data and saves the output locally for further analysis.\n",
    "\n",
    "**A few notes on this process:**\n",
    " * I have saved individual EKE files to make the processing faster (avoiding memory limitations on my laptop), at a cost of slight additional disk space. \n",
    " * To offset this, EKE files are re-sampled onto a monthly timeseries, which i think is fine for our purposes.\n",
    " * There are some crazy errors in the geostrophic velocity files. Under advice from Sally I have just eliminated  any EKE values  exceeding 2 m^2/s^2.\n",
    " * Processing seemed to all run smoothly, as far as I can tell.\n",
    " \n",
    "**AH - 11 April 2019**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import IPython.display\n",
    "import pandas as pd\n",
    "import cmocean as cm\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cft\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:33377</li>\n",
       "  <li><b>Dashboard: </b><a href='/proxy/8787/status' target='_blank'>/proxy/8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>68.72 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:33377' processes=8 threads=16, memory=68.72 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(n_workers=8)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HardDisk = '/g/data/v45/amh157/OCCIPUT/'\n",
    "EnsembleDir = 'geouv/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only need to load grid once\n",
    "gridfilename = HardDisk+'ORCA025.L75-MJM101.1_mesh_hgr.nc'\n",
    "gridds = xr.open_dataset(gridfilename)\n",
    "lon = gridds.nav_lon.isel(y=0).values.copy()\n",
    "lon[:430] = lon[:430]-360\n",
    "lat = gridds.nav_lat.isel(x=387).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now doing 001 - 1979\n",
      "Now doing 001 - 1980\n",
      "Now doing 001 - 1981\n",
      "Now doing 001 - 1982\n",
      "Now doing 001 - 1983\n",
      "Now doing 001 - 1984\n",
      "Now doing 001 - 1985\n",
      "Now doing 001 - 1986\n",
      "Now doing 001 - 1987\n",
      "Now doing 001 - 1988\n",
      "Now doing 001 - 1989\n",
      "Now doing 001 - 1990\n",
      "Now doing 001 - 1991\n",
      "Now doing 001 - 1992\n",
      "Now doing 001 - 1993\n",
      "Now doing 001 - 1994\n",
      "Now doing 001 - 1995\n",
      "Now doing 001 - 1996\n",
      "Now doing 001 - 1997\n",
      "Now doing 001 - 1998\n",
      "Now doing 001 - 1999\n",
      "Now doing 001 - 2000\n",
      "Now doing 001 - 2001\n",
      "Now doing 001 - 2002\n",
      "Now doing 001 - 2003\n",
      "Now doing 001 - 2004\n",
      "Now doing 001 - 2005\n",
      "Now doing 001 - 2006\n",
      "Now doing 001 - 2007\n",
      "Now doing 001 - 2008\n",
      "Now doing 001 - 2009\n",
      "Now doing 001 - 2010\n",
      "Now doing 001 - 2011\n",
      "Now doing 001 - 2012\n",
      "Now doing 001 - 2013\n",
      "Now doing 001 - 2014\n",
      "Now doing 001 - 2015\n",
      "Now doing 002 - 1979\n",
      "Now doing 002 - 1980\n",
      "Now doing 002 - 1981\n",
      "Now doing 002 - 1982\n",
      "Now doing 002 - 1983\n",
      "Now doing 002 - 1984\n",
      "Now doing 002 - 1985\n",
      "Now doing 002 - 1986\n",
      "Now doing 002 - 1987\n",
      "Now doing 002 - 1988\n",
      "Now doing 002 - 1989\n",
      "Now doing 002 - 1990\n",
      "Now doing 002 - 1991\n",
      "Now doing 002 - 1992\n",
      "Now doing 002 - 1993\n",
      "Now doing 002 - 1994\n",
      "Now doing 002 - 1995\n",
      "Now doing 002 - 1996\n",
      "Now doing 002 - 1997\n",
      "Now doing 002 - 1998\n",
      "Now doing 002 - 1999\n",
      "Now doing 002 - 2000\n",
      "Now doing 002 - 2001\n",
      "Now doing 002 - 2002\n",
      "Now doing 002 - 2003\n",
      "Now doing 002 - 2004\n",
      "Now doing 002 - 2005\n",
      "Now doing 002 - 2006\n",
      "Now doing 002 - 2007\n",
      "Now doing 002 - 2008\n",
      "Now doing 002 - 2009\n",
      "Now doing 002 - 2010\n",
      "Now doing 002 - 2011\n",
      "Now doing 002 - 2012\n",
      "Now doing 002 - 2013\n",
      "Now doing 002 - 2014\n",
      "Now doing 002 - 2015\n",
      "Now doing 003 - 1979\n",
      "Now doing 003 - 1980\n",
      "Now doing 003 - 1981\n",
      "Now doing 003 - 1982\n",
      "Now doing 003 - 1983\n",
      "Now doing 003 - 1984\n",
      "Now doing 003 - 1985\n",
      "Now doing 003 - 1986\n",
      "Now doing 003 - 1987\n",
      "Now doing 003 - 1988\n",
      "Now doing 003 - 1989\n",
      "Now doing 003 - 1990\n",
      "Now doing 003 - 1991\n",
      "Now doing 003 - 1992\n",
      "Now doing 003 - 1993\n",
      "Now doing 003 - 1994\n",
      "Now doing 003 - 1995\n",
      "Now doing 003 - 1996\n",
      "Now doing 003 - 1997\n",
      "Now doing 003 - 1998\n",
      "Now doing 003 - 1999\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for ii in range(1,51):\n",
    "    for year in range(1979,2016):\n",
    "        Year = '%d' % year\n",
    "        i00 = '%03d' % ii\n",
    "        print('Now doing '+i00+' - '+ Year)\n",
    "\n",
    "        Member = 'e'+i00\n",
    "        ufilename = HardDisk+EnsembleDir+Member+'/ugeo_'+i00+'_'+Year+'.nc'\n",
    "        vfilename = HardDisk+EnsembleDir+Member+'/vgeo_'+i00+'_'+Year+'.nc'\n",
    "        ekefilename = HardDisk+'processed_eke/eke_'+i00+'_'+Year+'.nc'\n",
    "\n",
    "        uds = xr.open_dataset(ufilename)\n",
    "        vds = xr.open_dataset(vfilename)\n",
    "\n",
    "        u=uds.vozocrtx.values\n",
    "        u2 = np.empty([73,1021,1442])\n",
    "        u2[:,1:,:] = 0.5*(u[:,:-1,:]+u[:,1:,:])\n",
    "        u2[:,0,:] = u[:,0,:]\n",
    "        u2 = u2*u2\n",
    "    \n",
    "        v=vds.vomecrty.values\n",
    "        v2 = np.empty([73,1021,1442])\n",
    "        v2[:,:,1:] = 0.5*(v[:,:,:-1]+v[:,:,1:])\n",
    "        v2[:,:,0] = 0.5*(v[:,:,-1]+v[:,:,0])\n",
    "        v2 = v2*v2\n",
    "\n",
    "        eke = 0.5*(u2+v2)\n",
    "        # FUDGE - reset funny values to zero\n",
    "        eke[eke>2] = 0\n",
    "        ekeda  = xr.DataArray(eke[:,:-1,1:], coords=[('time', uds.time_counter.values), \n",
    "                                            ('lat', lat[:-1]),\n",
    "                                            ('lon', lon[1:])], name='EKE',)\n",
    "\n",
    "        eke_monthly = ekeda.resample(time='M').mean('time')    \n",
    "        eke_monthly.to_netcdf(ekefilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now doing 1979\n",
      "Now doing 1980\n",
      "Now doing 1981\n",
      "Now doing 1982\n",
      "Now doing 1983\n",
      "Now doing 1984\n",
      "Now doing 1985\n",
      "Now doing 1986\n",
      "Now doing 1987\n",
      "Now doing 1988\n",
      "Now doing 1989\n",
      "Now doing 1990\n",
      "Now doing 1991\n",
      "Now doing 1992\n",
      "Now doing 1993\n",
      "Now doing 1994\n",
      "Now doing 1995\n",
      "Now doing 1996\n",
      "Now doing 1997\n",
      "Now doing 1998\n",
      "Now doing 1999\n",
      "Now doing 2000\n",
      "Now doing 2001\n",
      "Now doing 2002\n",
      "Now doing 2003\n",
      "Now doing 2004\n",
      "Now doing 2005\n",
      "Now doing 2006\n",
      "Now doing 2007\n",
      "Now doing 2008\n",
      "Now doing 2009\n",
      "Now doing 2010\n",
      "Now doing 2011\n",
      "Now doing 2012\n",
      "Now doing 2013\n",
      "Now doing 2014\n",
      "Now doing 2015\n",
      "CPU times: user 8min 6s, sys: 2min, total: 10min 7s\n",
      "Wall time: 14min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for year in range(1979,2016):\n",
    "    Year = '%d' % year\n",
    "    print('Now doing '+ Year)\n",
    "\n",
    "    tauxfilename = HardDisk+EnsembleDir+'taux/'+'ORCA025.L75-OCCITENS.001_y'+Year+'.5d_gridU.nc'\n",
    "    tauyfilename = HardDisk+EnsembleDir+'tauy/'+'ORCA025.L75-OCCITENS.001_y'+Year+'.5d_gridV.nc'\n",
    "    taufilename = HardDisk+EnsembleDir+'tau/'+'/tau_'+Year+'.nc'\n",
    "\n",
    "    tauxds = xr.open_dataset(tauxfilename)\n",
    "    tauyds = xr.open_dataset(tauyfilename)\n",
    "\n",
    "    # first, on v grid:\n",
    "    tauy=tauyds.sometauy.values\n",
    "    tauy2 = np.empty([73,1021,1442])\n",
    "    tauy2[:,1:,:] = 0.5*(tauy[:,:-1,:]+tauy[:,1:,:])\n",
    "    tauy2[:,0,:] = tauy[:,0,:]\n",
    "    tauy2 = tauy2*tauy2\n",
    "    \n",
    "    taux=tauxds.sozotaux.values\n",
    "    taux2 = np.empty([73,1021,1442])\n",
    "    taux2[:,:,1:] = 0.5*(taux[:,:,:-1]+taux[:,:,1:])\n",
    "    taux2[:,:,0] = 0.5*(taux[:,:,-1]+taux[:,:,0])\n",
    "    taux2 = taux2*taux2\n",
    "\n",
    "    tau = (taux2+tauy2)**0.5\n",
    "    tauda  = xr.DataArray(tau[:,:-1,1:], coords=[('time', tauxds.time_counter.values), \n",
    "                                            ('lat', lat[:-1]),\n",
    "                                            ('lon', lon[1:])], name='tau',)\n",
    "\n",
    "    tau_monthly = tauda.resample(time='M').mean('time')    \n",
    "    tau_monthly.to_netcdf(taufilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
